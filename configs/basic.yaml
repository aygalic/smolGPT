# configs/basic.yaml
seed_everything: 123
    
model:
  n_embed: 128
  block_size: 256
  n_heads: 4
  n_layer: 2
  dropout: 0.2
  learning_rate: 3e-4
  vocab_size : 65

data:
  path_to_dir: "./data/corpus.txt"
  batch_size: 64
  block_size: 256
  tokenizer_type: "ASCII"
  tokenizer_path: "tokenizer/vocab/"
  predict_prompt: "hello"

trainer:
  accelerator: "mps"
  max_steps: 5000
  enable_checkpointing: true
  default_root_dir: "checkpoints"
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "checkpoints"
        filename: "ASCII-transformer-{step:02d}"
        save_top_k: 1
        monitor: "train_loss"
        mode: "min"
        save_last: true
        every_n_train_steps: 10  # Save more frequently for testing
    - class_path: smolgpt.utils.custom_callback.PredictionOutputCallback
      init_args: {}
    - class_path: smolgpt.utils.custom_callback.AutoLoadLastCheckpointCallback
      init_args: {tokenizer_type : "ASCII"}
